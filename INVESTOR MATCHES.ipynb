{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3111a16-05e2-4cd7-b9b5-992cf681ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashish.ahirwar\\AppData\\Local\\Temp\\ipykernel_14100\\4028665715.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  order_book_df = pd.read_sql(order_book_query, conn)\n",
      "C:\\Users\\ashish.ahirwar\\AppData\\Local\\Temp\\ipykernel_14100\\4028665715.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  transactions_df = pd.read_sql(transactions_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Results:\n",
      "Excel File Created\n",
      "\n",
      "Found 0 records with matching transactions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "import sqlalchemy\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"\n",
    "    Process MF order book and transactions data according to specified business rules.\n",
    "    \n",
    "    Args:\n",
    "        server (str): SQL server name\n",
    "        database (str): Database name\n",
    "        username (str): Database username\n",
    "        password (str): Database password\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        conn_str = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "        # conn_str = sqlalchemy.create_engine(\n",
    "                    # f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "                    #     )\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        # conn = conn_str\n",
    "        \n",
    "        # Step 1: Fetch unique regno entries from mf_order_book with status 'Accepted'\n",
    "        order_book_query = \"\"\"\n",
    "        SELECT DISTINCT regno, investorcode, schemename, foliono, CAST(LEFT(regdate, 10) AS DATE) AS regdate\n",
    "        FROM mf_order_book\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        \n",
    "        # Read data into pandas\n",
    "        order_book_df = pd.read_sql(order_book_query, conn)\n",
    "        \n",
    "        if order_book_df.empty:\n",
    "            print(\"No accepted orders found in mf_order_book\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Step 2: Preprocess folio numbers (take left part before '/')\n",
    "        order_book_df['processed_folio'] = order_book_df['foliono'].apply(\n",
    "            lambda x: x.split('/')[0] if x and '/' in x else (x if x else None)\n",
    "        )\n",
    "        \n",
    "        # Step 3: Fetch transactions data\n",
    "        transactions_query = \"SELECT investorcode, schemename, foliono, trandate FROM MUTUALFUND_TRANSACTIONS\"\n",
    "        transactions_df = pd.read_sql(transactions_query, conn)\n",
    "        \n",
    "        # Preprocess transaction folio numbers similarly\n",
    "        transactions_df['processed_folio'] = transactions_df['foliono'].apply(\n",
    "            lambda x: x.split('/')[0] if x and '/' in x else (x if x else None)\n",
    "        )\n",
    "        \n",
    "        # Initialize result dataframe\n",
    "        results = []\n",
    "        \n",
    "        # Step 4: Process each order book entry\n",
    "        for _, row in order_book_df.iterrows():\n",
    "            # Create matching conditions\n",
    "            condition1 = (\n",
    "                (transactions_df['investorcode'] == row['investorcode']) &\n",
    "                (transactions_df['schemename'] == row['schemename']) &\n",
    "                (transactions_df['processed_folio'] == row['processed_folio']) &\n",
    "                (pd.notna(row['processed_folio']))\n",
    "            )\n",
    "            \n",
    "            condition2 = (\n",
    "                (transactions_df['investorcode'] == row['investorcode']) &\n",
    "                (transactions_df['schemename'] == row['schemename']) &\n",
    "                (pd.isna(row['processed_folio']))\n",
    "            )\n",
    "            \n",
    "            # Find matching transactions\n",
    "            matching_trans = transactions_df[condition1 | condition2]\n",
    "            \n",
    "            # Filter transactions after registration date\n",
    "            if not pd.isna(row['regdate']):\n",
    "                matching_trans = matching_trans[\n",
    "                    matching_trans['trandate'] >= row['regdate']\n",
    "                ]\n",
    "            \n",
    "            # Find the earliest transaction date if any matches\n",
    "            if not matching_trans.empty:\n",
    "                first_trandate = matching_trans['trandate'].min()\n",
    "                results.append({\n",
    "                    'regno': row['regno'],\n",
    "                    'investorcode': row['investorcode'],\n",
    "                    'schemename': row['schemename'],\n",
    "                    'foliono': row['foliono'],\n",
    "                    'regdate': row['regdate'],\n",
    "                    'first_trandate': first_trandate,\n",
    "                    'has_matching_transaction': True\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    'regno': row['regno'],\n",
    "                    'investorcode': row['investorcode'],\n",
    "                    'schemename': row['schemename'],\n",
    "                    'foliono': row['foliono'],\n",
    "                    'regdate': row['regdate'],\n",
    "                    'first_trandate': None,\n",
    "                    'has_matching_transaction': False\n",
    "                })\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual database credentials\n",
    "    server = '192.168.100.55'\n",
    "    database = 'Wealthone'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        print(\"Processing completed. Results:\")\n",
    "        # print(result.head())\n",
    "        result.head()\n",
    "        result.to_excel('last_result.xlsx', index = False)\n",
    "        print(\"Excel File Created\")\n",
    "        \n",
    "        # You can now work with the result DataFrame\n",
    "        # For example, filter only records with matching transactions\n",
    "        matched_records = result[result['has_matching_transaction']]\n",
    "        print(f\"\\nFound {len(matched_records)} records with matching transactions.\")\n",
    "    else:\n",
    "        print(\"No results returned from processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c91c9d-e0b6-4caa-b29a-c655622757ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed successfully!\n",
      "Total records processed: 1475\n",
      "Records with matches: 0\n",
      "Results saved to: mf_matching_results_20250414_124750.xlsx\n",
      "\n",
      "Sample of non-matching records for verification:\n",
      "       regno investorcode                                         schemename\n",
      "0  100257205      RA10003  DSP INDIA T.I.G.E.R. FUND - REGULAR PLAN - IDC...\n",
      "1  100258790    KUN105412    HDFC MID-CAP OPPORTUNITIES FUND - GROWTH OPTION\n",
      "2  100401671       GK2003  MIRAE ASSET LARGE & MIDCAP FUND - REGULAR PLAN...\n",
      "3  100994083      LS10008  NIPPON INDIA LARGE CAP FUND - GROWTH PLAN - GR...\n",
      "4  100994194      LS10008    HDFC MANUFACTURING FUND - REGULAR PLAN - GROWTH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"\n",
    "    Process MF order book and transactions data with accurate matching logic.\n",
    "    \n",
    "    Args:\n",
    "        server (str): SQL server name\n",
    "        database (str): Database name\n",
    "        username (str): Database username\n",
    "        password (str): Database password\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Results with matching transactions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Suppress SQLAlchemy warnings\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        \n",
    "        # Step 1: Fetch unique accepted orders\n",
    "        order_book_query = \"\"\"\n",
    "        SELECT DISTINCT regno, investorcode, schemename, foliono, regdate\n",
    "        FROM mf_order_book\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_book_df = pd.read_sql(order_book_query, engine)\n",
    "        \n",
    "        if order_book_df.empty:\n",
    "            print(\"No accepted orders found in mf_order_book\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Step 2: Preprocess folio numbers\n",
    "        def process_folio(x):\n",
    "            if pd.isna(x):\n",
    "                return None\n",
    "            x = str(x).strip()\n",
    "            return x.split('/')[0] if '/' in x else x\n",
    "        \n",
    "        order_book_df['processed_folio'] = order_book_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Step 3: Fetch transactions data\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT investorcode, schemename, foliono, trandate \n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \"\"\"\n",
    "        transactions_df = pd.read_sql(transactions_query, engine)\n",
    "        transactions_df['processed_folio'] = transactions_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Convert dates to datetime if they're strings\n",
    "        for df in [order_book_df, transactions_df]:\n",
    "            if 'regdate' in df.columns and df['regdate'].dtype == object:\n",
    "                df['regdate'] = pd.to_datetime(df['regdate'])\n",
    "            if 'trandate' in df.columns and df['trandate'].dtype == object:\n",
    "                df['trandate'] = pd.to_datetime(df['trandate'])\n",
    "\n",
    "        # Initialize result list\n",
    "        results = []\n",
    "        \n",
    "        # Step 4: Process each order with accurate matching\n",
    "        for _, order in order_book_df.iterrows():\n",
    "            # Base matching conditions\n",
    "            base_match = (\n",
    "                (transactions_df['investorcode'] == order['investorcode']) &\n",
    "                (transactions_df['schemename'] == order['schemename'])\n",
    "            )\n",
    "            \n",
    "            # Folio matching condition\n",
    "            if pd.notna(order['processed_folio']):\n",
    "                folio_match = (transactions_df['processed_folio'] == order['processed_folio'])\n",
    "                matching_trans = transactions_df[base_match & folio_match]\n",
    "            else:\n",
    "                matching_trans = transactions_df[base_match]\n",
    "            \n",
    "            # Date filtering\n",
    "            if pd.notna(order['regdate']):\n",
    "                matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "            \n",
    "            # Prepare result\n",
    "            result = {\n",
    "                'regno': order['regno'],\n",
    "                'investorcode': order['investorcode'],\n",
    "                'schemename': order['schemename'],\n",
    "                'foliono': order['foliono'],\n",
    "                'regdate': order['regdate'],\n",
    "                'first_trandate': None,\n",
    "                'has_matching_transaction': False,\n",
    "                'matching_transaction_count': 0\n",
    "            }\n",
    "            \n",
    "            if not matching_trans.empty:\n",
    "                first_trandate = matching_trans['trandate'].min()\n",
    "                result.update({\n",
    "                    'first_trandate': first_trandate,\n",
    "                    'has_matching_transaction': True,\n",
    "                    'matching_transaction_count': len(matching_trans)\n",
    "                })\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    server = '192.168.100.55'\n",
    "    database = 'WEALTHONE'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    # Process data\n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        print(\"Processing completed successfully!\")\n",
    "        print(f\"Total records processed: {len(result)}\")\n",
    "        print(f\"Records with matches: {result['has_matching_transaction'].sum()}\")\n",
    "        \n",
    "        # Save to Excel with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"mf_matching_results_{timestamp}.xlsx\"\n",
    "        result.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample of non-matching records for verification\n",
    "        non_matches = result[~result['has_matching_transaction']]\n",
    "        if not non_matches.empty:\n",
    "            print(\"\\nSample of non-matching records for verification:\")\n",
    "            print(non_matches[['regno', 'investorcode', 'schemename']].head())\n",
    "    else:\n",
    "        print(\"No results returned from processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c354cfb3-e3f8-4979-9eaa-ba14cbd85620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'Timestamp' object is not iterable\n",
      "No results returned from processing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"\n",
    "    Process MF order book and transactions data with precise matching logic.\n",
    "    \n",
    "    Args:\n",
    "        server (str): SQL server name\n",
    "        database (str): Database name\n",
    "        username (str): Database username\n",
    "        password (str): Database password\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Results with matching transactions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Suppress warnings\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        \n",
    "        # Step 1: Fetch accepted orders\n",
    "        order_book_query = \"\"\"\n",
    "        SELECT DISTINCT regno, investorcode, schemename, foliono, regdate\n",
    "        FROM mf_order_book\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_book_df = pd.read_sql(order_book_query, engine)\n",
    "        \n",
    "        if order_book_df.empty:\n",
    "            print(\"No accepted orders found in mf_order_book\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Step 2: Preprocess folio numbers\n",
    "        def process_folio(x):\n",
    "            if pd.isna(x):\n",
    "                return None\n",
    "            x = str(x).strip()\n",
    "            return x.split('/')[0] if '/' in x else x\n",
    "        \n",
    "        order_book_df['processed_folio'] = order_book_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Step 3: Fetch transactions data\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT investorcode, schemename, foliono, trandate \n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \"\"\"\n",
    "        transactions_df = pd.read_sql(transactions_query, engine)\n",
    "        transactions_df['processed_folio'] = transactions_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Convert dates to datetime objects\n",
    "        order_book_df['regdate'] = pd.to_datetime(order_book_df['regdate'])\n",
    "        transactions_df['trandate'] = pd.to_datetime(transactions_df['trandate'])\n",
    "\n",
    "        # Initialize result list\n",
    "        results = []\n",
    "        \n",
    "        # Step 4: Process each order with precise matching\n",
    "        for _, order in order_book_df.iterrows():\n",
    "            # Base matching conditions\n",
    "            investor_match = (transactions_df['investorcode'] == order['investorcode'])\n",
    "            scheme_match = (transactions_df['schemename'].str.strip().str.upper() == \n",
    "                          order['schemename'].strip().upper())\n",
    "            \n",
    "            # Folio matching (case insensitive and with/without prefix)\n",
    "            folio_condition = True  # Default to True if no folio\n",
    "            if pd.notna(order['processed_folio']):\n",
    "                folio_condition = (\n",
    "                    transactions_df['processed_folio'].str.strip().str.upper() == \n",
    "                    order['processed_folio'].strip().upper()\n",
    "                )\n",
    "            \n",
    "            # Combine all conditions\n",
    "            matching_trans = transactions_df[\n",
    "                investor_match & \n",
    "                scheme_match & \n",
    "                folio_condition\n",
    "            ]\n",
    "            \n",
    "            # Filter transactions after registration date\n",
    "            if pd.notna(order['regdate']):\n",
    "                matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "            \n",
    "            # Prepare result\n",
    "            result = {\n",
    "                'regno': order['regno'],\n",
    "                'investorcode': order['investorcode'],\n",
    "                'schemename': order['schemename'],\n",
    "                'foliono': order['foliono'],\n",
    "                'regdate': order['regdate'],\n",
    "                'first_trandate': None,\n",
    "                'has_matching_transaction': False,\n",
    "                'matching_transaction_count': 0,\n",
    "                'all_matching_dates': []\n",
    "            }\n",
    "            \n",
    "            if not matching_trans.empty:\n",
    "                # Get all matching dates sorted\n",
    "                all_dates = sorted(matching_trans['trandate'].unique())\n",
    "                first_trandate = all_dates[0]\n",
    "                \n",
    "                result.update({\n",
    "                    'first_trandate': first_trandate,\n",
    "                    'has_matching_transaction': True,\n",
    "                    'matching_transaction_count': len(matching_trans),\n",
    "                    'all_matching_dates': \", \".join([str(d.date()) for d in all_dates])\n",
    "                })\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    server = '192.168.100.55'\n",
    "    database = 'Wealthone'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    # Process data\n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        print(\"Processing completed successfully!\")\n",
    "        print(f\"Total records processed: {len(result)}\")\n",
    "        print(f\"Records with matches: {result['has_matching_transaction'].sum()}\")\n",
    "        \n",
    "        # Save to Excel with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"mf_matching_results_{timestamp}.xlsx\"\n",
    "        \n",
    "        # Format dates for better Excel display\n",
    "        result['regdate'] = result['regdate'].dt.strftime('%Y-%m-%d')\n",
    "        result['first_trandate'] = result['first_trandate'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        result.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample of matching records for verification\n",
    "        matches = result[result['has_matching_transaction']]\n",
    "        if not matches.empty:\n",
    "            print(\"\\nSample of matching records for verification:\")\n",
    "            print(matches[['regno', 'investorcode', 'schemename', \n",
    "                          'regdate', 'first_trandate']].head())\n",
    "    else:\n",
    "        print(\"No results returned from processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32a9296b-a5be-4de3-9ca7-5051547ce813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: \"None of [Index([21981, 26146, 29936, 151282, 153476, 155001], dtype='int64')] are in the [columns]\"\n",
      "No results returned from processing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "def normalize_scheme_name(name):\n",
    "    \"\"\"\n",
    "    Normalize scheme names for flexible matching by:\n",
    "    - Converting to lowercase\n",
    "    - Removing extra spaces and punctuation\n",
    "    - Standardizing common variations\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    name = str(name).lower()\n",
    "    \n",
    "    # Remove special characters except spaces and hyphens\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    \n",
    "    # Standardize common variations\n",
    "    replacements = {\n",
    "        'regular plan': 'regular',\n",
    "        'growth option': 'growth',\n",
    "        'idcw reinvestment': 'idcw',\n",
    "        'dividend reinvestment': 'idcw',\n",
    "        'direct plan': 'direct'\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    name = ' '.join(name.split())\n",
    "    \n",
    "    return name.strip()\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"\n",
    "    Process MF order book and transactions data with flexible scheme name matching.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        \n",
    "        # Step 1: Fetch accepted orders\n",
    "        order_book_query = \"\"\"\n",
    "        SELECT DISTINCT regno, investorcode, schemename, foliono, regdate\n",
    "        FROM mf_order_book\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_book_df = pd.read_sql(order_book_query, engine)\n",
    "        \n",
    "        if order_book_df.empty:\n",
    "            print(\"No accepted orders found in mf_order_book\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Step 2: Preprocess data\n",
    "        def process_folio(x):\n",
    "            if pd.isna(x):\n",
    "                return None\n",
    "            x = str(x).strip()\n",
    "            return x.split('/')[0] if '/' in x else x\n",
    "        \n",
    "        # Process folio numbers and normalize scheme names\n",
    "        order_book_df['processed_folio'] = order_book_df['foliono'].apply(process_folio)\n",
    "        order_book_df['normalized_scheme'] = order_book_df['schemename'].apply(normalize_scheme_name)\n",
    "        \n",
    "        # Step 3: Fetch transactions data\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT investorcode, schemename, foliono, trandate \n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \"\"\"\n",
    "        transactions_df = pd.read_sql(transactions_query, engine)\n",
    "        transactions_df['processed_folio'] = transactions_df['foliono'].apply(process_folio)\n",
    "        transactions_df['normalized_scheme'] = transactions_df['schemename'].apply(normalize_scheme_name)\n",
    "        \n",
    "        # Convert dates to datetime objects\n",
    "        order_book_df['regdate'] = pd.to_datetime(order_book_df['regdate'])\n",
    "        transactions_df['trandate'] = pd.to_datetime(transactions_df['trandate'])\n",
    "\n",
    "        # Initialize result list\n",
    "        results = []\n",
    "        \n",
    "        # Step 4: Process each order with flexible matching\n",
    "        for _, order in order_book_df.iterrows():\n",
    "            # Base matching conditions\n",
    "            investor_match = (transactions_df['investorcode'] == order['investorcode'])\n",
    "            scheme_match = (transactions_df['normalized_scheme'] == order['normalized_scheme'])\n",
    "            \n",
    "            # Folio matching\n",
    "            folio_condition = True  # Default to True if no folio\n",
    "            if pd.notna(order['processed_folio']):\n",
    "                folio_condition = (\n",
    "                    transactions_df['processed_folio'].astype(str).str.strip().str.lower() == \n",
    "                    order['processed_folio'].strip().lower()\n",
    "                )\n",
    "            \n",
    "            # Combine all conditions\n",
    "            matching_trans = transactions_df[\n",
    "                investor_match & \n",
    "                scheme_match & \n",
    "                folio_condition\n",
    "            ]\n",
    "            \n",
    "            # Filter transactions after registration date\n",
    "            if pd.notna(order['regdate']):\n",
    "                matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "            \n",
    "            # Prepare result\n",
    "            result = {\n",
    "                'regno': order['regno'],\n",
    "                'investorcode': order['investorcode'],\n",
    "                'schemename': order['schemename'],\n",
    "                'transaction_schemename': ', '.join(transactions_df[matching_trans.index]['schemename'].unique()),\n",
    "                'foliono': order['foliono'],\n",
    "                'regdate': order['regdate'],\n",
    "                'first_trandate': None,\n",
    "                'has_matching_transaction': False,\n",
    "                'matching_transaction_count': 0,\n",
    "                'all_matching_dates': []\n",
    "            }\n",
    "            \n",
    "            if not matching_trans.empty:\n",
    "                # Get all matching dates sorted\n",
    "                all_dates = sorted(matching_trans['trandate'].unique())\n",
    "                first_trandate = all_dates[0]\n",
    "                \n",
    "                result.update({\n",
    "                    'first_trandate': first_trandate,\n",
    "                    'has_matching_transaction': True,\n",
    "                    'matching_transaction_count': len(matching_trans),\n",
    "                    'all_matching_dates': \", \".join([str(d.date()) for d in all_dates])\n",
    "                })\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    server = '192.168.100.55'\n",
    "    database = 'Wealthone'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    # Process data\n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        print(\"Processing completed successfully!\")\n",
    "        print(f\"Total records processed: {len(result)}\")\n",
    "        print(f\"Records with matches: {result['has_matching_transaction'].sum()}\")\n",
    "        \n",
    "        # Save to Excel with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"mf_matching_results_{timestamp}.xlsx\"\n",
    "        \n",
    "        # Format dates for better Excel display\n",
    "        date_cols = ['regdate', 'first_trandate']\n",
    "        for col in date_cols:\n",
    "            if col in result.columns:\n",
    "                result[col] = result[col].apply(lambda x: x.strftime('%Y-%m-%d') if not pd.isna(x) else '')\n",
    "        \n",
    "        result.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample records for verification\n",
    "        print(\"\\nSample records for verification:\")\n",
    "        sample_cols = ['regno', 'investorcode', 'schemename', 'transaction_schemename', \n",
    "                      'regdate', 'first_trandate', 'matching_transaction_count']\n",
    "        print(result[sample_cols].head(10))\n",
    "    else:\n",
    "        print(\"No results returned from processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41d2ff91-09be-4251-99a1-3782f0bb5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed but no results returned. Check log file for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='mf_matching.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for comparison by removing special chars and standardizing case\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)  # Remove special chars except hyphens\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces\n",
    "    return text\n",
    "\n",
    "def normalize_scheme_name(name):\n",
    "    \"\"\"Special normalization for mutual fund scheme names\"\"\"\n",
    "    name = normalize_text(name)\n",
    "    \n",
    "    # Standardize common variations\n",
    "    replacements = {\n",
    "        'regular plan': 'regular',\n",
    "        'growth option': 'growth',\n",
    "        'idcw reinvestment': 'idcw',\n",
    "        'dividend reinvestment': 'idcw',\n",
    "        'direct plan': 'direct',\n",
    "        'fund -': 'fund',\n",
    "        'plan -': 'plan'\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    \n",
    "    return name.strip()\n",
    "\n",
    "def process_folio(folio):\n",
    "    \"\"\"Process folio numbers consistently\"\"\"\n",
    "    if pd.isna(folio):\n",
    "        return None\n",
    "    folio = str(folio).strip()\n",
    "    return folio.split('/')[0] if '/' in folio else folio\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"Create and return a SQLAlchemy engine with error handling\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            f\"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        return create_engine(conn_str)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_dataframes(order_df, trans_df):\n",
    "    \"\"\"Validate the structure of input DataFrames\"\"\"\n",
    "    required_order_cols = {'regno', 'investorcode', 'schemename', 'foliono', 'regdate'}\n",
    "    required_trans_cols = {'investorcode', 'schemename', 'foliono', 'trandate'}\n",
    "    \n",
    "    if not required_order_cols.issubset(order_df.columns):\n",
    "        missing = required_order_cols - set(order_df.columns)\n",
    "        raise ValueError(f\"Order book missing columns: {missing}\")\n",
    "    \n",
    "    if not required_trans_cols.issubset(trans_df.columns):\n",
    "        missing = required_trans_cols - set(trans_df.columns)\n",
    "        raise ValueError(f\"Transactions missing columns: {missing}\")\n",
    "    \n",
    "    logger.info(\"Data validation passed\")\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        warnings.filterwarnings('ignore')\n",
    "        logger.info(\"Starting MF transaction processing\")\n",
    "        \n",
    "        # Establish database connection\n",
    "        engine = get_db_connection(server, database, username, password)\n",
    "        \n",
    "        # Step 1: Fetch accepted orders\n",
    "        logger.info(\"Fetching order book data\")\n",
    "        order_book_query = \"\"\"\n",
    "        SELECT DISTINCT regno, investorcode, amcid, foliono, regdate\n",
    "        FROM MF_LIVE\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_book_df = pd.read_sql(order_book_query, engine)\n",
    "        \n",
    "        if order_book_df.empty:\n",
    "            logger.warning(\"No accepted orders found in mf_order_book\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Step 2: Fetch transactions data\n",
    "        logger.info(\"Fetching transactions data\")\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT investorcode, amcid, foliono, trandate \n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \"\"\"\n",
    "        transactions_df = pd.read_sql(transactions_query, engine)\n",
    "        \n",
    "        # Validate data structure\n",
    "        validate_dataframes(order_book_df, transactions_df)\n",
    "        \n",
    "        # Step 3: Preprocess data\n",
    "        logger.info(\"Preprocessing data\")\n",
    "        \n",
    "        # Process folio numbers\n",
    "        order_book_df['processed_folio'] = order_book_df['foliono'].apply(process_folio)\n",
    "        transactions_df['processed_folio'] = transactions_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Normalize scheme names\n",
    "        order_book_df['normalized_scheme'] = order_book_df['amcid'].apply(normalize_scheme_name)\n",
    "        transactions_df['normalized_scheme'] = transactions_df['amcid'].apply(normalize_scheme_name)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        order_book_df['regdate'] = pd.to_datetime(order_book_df['regdate'])\n",
    "        transactions_df['trandate'] = pd.to_datetime(transactions_df['trandate'])\n",
    "        \n",
    "        # Initialize results\n",
    "        results = []\n",
    "        match_count = 0\n",
    "        \n",
    "        # Step 4: Process each order\n",
    "        logger.info(f\"Processing {len(order_book_df)} orders\")\n",
    "        for idx, order in order_book_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                investor_cond = (transactions_df['investorcode'] == order['investorcode'])\n",
    "                scheme_cond = (transactions_df['normalized_scheme'] == order['normalized_scheme'])\n",
    "                \n",
    "                # Folio condition (skip if folio is null/empty)\n",
    "                folio_cond = True\n",
    "                if pd.notna(order['processed_folio']) and order['processed_folio'] != '':\n",
    "                    folio_cond = (\n",
    "                        transactions_df['processed_folio'].astype(str) == \n",
    "                        order['processed_folio'].astype(str)\n",
    "                    )\n",
    "                \n",
    "                # Combine conditions\n",
    "                matching_trans = transactions_df[investor_cond & scheme_cond & folio_cond]\n",
    "                \n",
    "                # Filter by date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'order_schemename': order['amcid'],\n",
    "                    'order_folio': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'first_trandate': None,\n",
    "                    'has_matching_transaction': False,\n",
    "                    'match_count': 0,\n",
    "                    'matching_transaction_schemes': None,\n",
    "                    'matching_dates': None\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    match_count += 1\n",
    "                    first_date = matching_trans['trandate'].min()\n",
    "                    unique_schemes = matching_trans['amcid'].unique()\n",
    "                    \n",
    "                    result.update({\n",
    "                        'first_trandate': first_date,\n",
    "                        'has_matching_transaction': True,\n",
    "                        'match_count': len(matching_trans),\n",
    "                        'matching_transaction_schemes': ', '.join(unique_schemes),\n",
    "                        'matching_dates': ', '.join(\n",
    "                            matching_trans['trandate'].dt.strftime('%Y-%m-%d').sort_values().unique()\n",
    "                        )\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Processing complete. Found matches for {match_count}/{len(order_book_df)} orders\")\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Convert dates to strings for Excel output\n",
    "        date_cols = ['regdate', 'first_trandate']\n",
    "        for col in date_cols:\n",
    "            if col in result_df.columns:\n",
    "                result_df[col] = result_df[col].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\", exc_info=True)\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "            logger.info(\"Database connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuration\n",
    "        config = {\n",
    "            'server' : '192.168.100.55',\n",
    "            'database' : 'Wealthone',\n",
    "            'username' : 'aruhat',\n",
    "            'password' : 'aruhat'\n",
    "        }\n",
    "        \n",
    "        # Process data\n",
    "        logger.info(\"Starting main execution\")\n",
    "        result = process_mf_transactions(**config)\n",
    "        \n",
    "        if not result.empty:\n",
    "            # Save results\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"mf_matching_results_{timestamp}.xlsx\"\n",
    "            \n",
    "            # Reorder columns for better readability\n",
    "            cols = [\n",
    "                'regno', 'investorcode', 'order_schemename', \n",
    "                'matching_transaction_schemes', 'order_folio',\n",
    "                'regdate', 'first_trandate', 'match_count',\n",
    "                'has_matching_transaction', 'matching_dates'\n",
    "            ]\n",
    "            cols = [c for c in cols if c in result.columns]\n",
    "            \n",
    "            result[cols].to_excel(output_file, index=False)\n",
    "            logger.info(f\"Results saved to {output_file}\")\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nProcessing Summary:\")\n",
    "            print(f\"Total orders processed: {len(result)}\")\n",
    "            print(f\"Orders with matches: {result['has_matching_transaction'].sum()}\")\n",
    "            print(f\"Output file: {output_file}\")\n",
    "            \n",
    "            # Show sample non-matches for verification\n",
    "            non_matches = result[~result['has_matching_transaction']]\n",
    "            if not non_matches.empty:\n",
    "                print(\"\\nSample non-matching orders for verification:\")\n",
    "                print(non_matches[['regno', 'investorcode', 'order_schemename']].head(5))\n",
    "        else:\n",
    "            logger.warning(\"No results returned\")\n",
    "            print(\"Processing completed but no results returned. Check log file for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in main execution: {str(e)}\", exc_info=True)\n",
    "        print(f\"An error occurred. Please check the log file for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "190ee8da-f87c-43ff-b707-0c8831342eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed but no results returned. Check log file for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='mf_amcid_matching.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def process_folio(folio):\n",
    "    \"\"\"Process folio numbers consistently\"\"\"\n",
    "    if pd.isna(folio):\n",
    "        return None\n",
    "    folio = str(folio).strip()\n",
    "    return folio.split('/')[0] if '/' in folio else folio\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"Create and return a SQLAlchemy engine\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            f\"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        return create_engine(conn_str)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_dataframes(order_df, trans_df):\n",
    "    \"\"\"Validate the structure of input DataFrames\"\"\"\n",
    "    required_order_cols = {'regno', 'investorcode', 'amcid', 'foliono', 'regdate'}\n",
    "    required_trans_cols = {'investorcode', 'amcid', 'foliono', 'trandate'}\n",
    "    \n",
    "    if not required_order_cols.issubset(order_df.columns):\n",
    "        missing = required_order_cols - set(order_df.columns)\n",
    "        raise ValueError(f\"Order book missing columns: {missing}\")\n",
    "    \n",
    "    if not required_trans_cols.issubset(trans_df.columns):\n",
    "        missing = required_trans_cols - set(trans_df.columns)\n",
    "        raise ValueError(f\"Transactions missing columns: {missing}\")\n",
    "    \n",
    "    logger.info(\"Data validation passed\")\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function using AMCID for exact matching\"\"\"\n",
    "    try:\n",
    "        warnings.filterwarnings('ignore')\n",
    "        logger.info(\"Starting MF transaction processing with AMCID matching\")\n",
    "        \n",
    "        # Establish database connection\n",
    "        engine = get_db_connection(server, database, username, password)\n",
    "        \n",
    "        # Step 1: Fetch accepted orders with AMCID\n",
    "        logger.info(\"Fetching order book data with AMCID\")\n",
    "        order_book_query = \"\"\"\n",
    "        SELECT DISTINCT o.regno, o.investorcode, o.foliono, o.regdate, l.amcid\n",
    "        FROM mf_order_book o\n",
    "        JOIN mf_live l ON o.schemename = l.schemename  -- Or appropriate join condition\n",
    "        WHERE o.orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_book_df = pd.read_sql(order_book_query, engine)\n",
    "        \n",
    "        if order_book_df.empty:\n",
    "            logger.warning(\"No accepted orders found in mf_order_book\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Step 2: Fetch transactions data with AMCID\n",
    "        logger.info(\"Fetching transactions data with AMCID\")\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT t.investorcode, t.foliono, t.trandate, l.amcid\n",
    "        FROM MUTUALFUND_TRANSACTIONS t\n",
    "        JOIN mf_live l ON t.schemename = l.schemename  -- Or appropriate join condition\n",
    "        \"\"\"\n",
    "        transactions_df = pd.read_sql(transactions_query, engine)\n",
    "        \n",
    "        # Validate data structure\n",
    "        validate_dataframes(order_book_df, transactions_df)\n",
    "        \n",
    "        # Step 3: Preprocess data\n",
    "        logger.info(\"Preprocessing data\")\n",
    "        \n",
    "        # Process folio numbers\n",
    "        order_book_df['processed_folio'] = order_book_df['foliono'].apply(process_folio)\n",
    "        transactions_df['processed_folio'] = transactions_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        order_book_df['regdate'] = pd.to_datetime(order_book_df['regdate'])\n",
    "        transactions_df['trandate'] = pd.to_datetime(transactions_df['trandate'])\n",
    "        \n",
    "        # Initialize results\n",
    "        results = []\n",
    "        match_count = 0\n",
    "        \n",
    "        # Step 4: Process each order using AMCID\n",
    "        logger.info(f\"Processing {len(order_book_df)} orders\")\n",
    "        for idx, order in order_book_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                investor_cond = (transactions_df['investorcode'] == order['investorcode'])\n",
    "                amcid_cond = (transactions_df['amcid'] == order['amcid'])\n",
    "                \n",
    "                # Folio condition (skip if folio is null/empty)\n",
    "                folio_cond = True\n",
    "                if pd.notna(order['processed_folio']) and order['processed_folio'] != '':\n",
    "                    folio_cond = (\n",
    "                        transactions_df['processed_folio'].astype(str) == \n",
    "                        order['processed_folio'].astype(str)\n",
    "                    )\n",
    "                \n",
    "                # Combine conditions\n",
    "                matching_trans = transactions_df[investor_cond & amcid_cond & folio_cond]\n",
    "                \n",
    "                # Filter by date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'order_folio': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'first_trandate': None,\n",
    "                    'has_matching_transaction': False,\n",
    "                    'match_count': 0,\n",
    "                    'matching_dates': None\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    match_count += 1\n",
    "                    first_date = matching_trans['trandate'].min()\n",
    "                    \n",
    "                    result.update({\n",
    "                        'first_trandate': first_date,\n",
    "                        'has_matching_transaction': True,\n",
    "                        'match_count': len(matching_trans),\n",
    "                        'matching_dates': ', '.join(\n",
    "                            matching_trans['trandate'].dt.strftime('%Y-%m-%d').sort_values().unique()\n",
    "                        )\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Processing complete. Found matches for {match_count}/{len(order_book_df)} orders\")\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Convert dates to strings for Excel output\n",
    "        date_cols = ['regdate', 'first_trandate']\n",
    "        for col in date_cols:\n",
    "            if col in result_df.columns:\n",
    "                result_df[col] = result_df[col].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\", exc_info=True)\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "            logger.info(\"Database connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuration\n",
    "        config = {\n",
    "            'server': '192.168.100.55',\n",
    "            'database': 'Wealthone',\n",
    "            'username': 'aruhat',\n",
    "            'password': 'aruhat'\n",
    "        }\n",
    "        \n",
    "        # Process data\n",
    "        logger.info(\"Starting main execution with AMCID matching\")\n",
    "        result = process_mf_transactions(**config)\n",
    "        \n",
    "        if not result.empty:\n",
    "            # Save results\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"mf_amcid_matching_results_{timestamp}.xlsx\"\n",
    "            \n",
    "            # Reorder columns for better readability\n",
    "            cols = [\n",
    "                'regno', 'investorcode', 'amcid', 'order_folio',\n",
    "                'regdate', 'first_trandate', 'match_count',\n",
    "                'has_matching_transaction', 'matching_dates'\n",
    "            ]\n",
    "            cols = [c for c in cols if c in result.columns]\n",
    "            \n",
    "            result[cols].to_excel(output_file, index=False)\n",
    "            logger.info(f\"Results saved to {output_file}\")\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nProcessing Summary:\")\n",
    "            print(f\"Total orders processed: {len(result)}\")\n",
    "            print(f\"Orders with matches: {result['has_matching_transaction'].sum()}\")\n",
    "            print(f\"Output file: {output_file}\")\n",
    "            \n",
    "            # Show sample non-matches for verification\n",
    "            non_matches = result[~result['has_matching_transaction']]\n",
    "            if not non_matches.empty:\n",
    "                print(\"\\nSample non-matching orders for verification:\")\n",
    "                print(non_matches[['regno', 'investorcode', 'amcid']].head(5))\n",
    "        else:\n",
    "            logger.warning(\"No results returned\")\n",
    "            print(\"Processing completed but no results returned. Check log file for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in main execution: {str(e)}\", exc_info=True)\n",
    "        print(f\"An error occurred. Please check the log file for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f87e868-8236-46cc-ab43-8e44f6563d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed with no results. Check log for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='mf_amcid_matching.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def process_folio(folio):\n",
    "    \"\"\"Process folio numbers consistently\"\"\"\n",
    "    if pd.isna(folio):\n",
    "        return None\n",
    "    folio = str(folio).strip()\n",
    "    return folio.split('/')[0] if '/' in folio else folio\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"Create and return a SQLAlchemy engine\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            f\"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        return create_engine(conn_str)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_dataframes(order_df, trans_df):\n",
    "    \"\"\"Validate the structure of input DataFrames\"\"\"\n",
    "    required_order_cols = {'regno', 'investorcode', 'amcid', 'foliono', 'regdate'}\n",
    "    required_trans_cols = {'investorcode', 'amcid', 'foliono', 'trandate'}\n",
    "    \n",
    "    if not required_order_cols.issubset(order_df.columns):\n",
    "        missing = required_order_cols - set(order_df.columns)\n",
    "        raise ValueError(f\"Order book missing columns: {missing}\")\n",
    "    \n",
    "    if not required_trans_cols.issubset(trans_df.columns):\n",
    "        missing = required_trans_cols - set(trans_df.columns)\n",
    "        raise ValueError(f\"Transactions missing columns: {missing}\")\n",
    "    \n",
    "    logger.info(\"Data validation passed\")\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function using only AMCID for scheme matching\"\"\"\n",
    "    try:\n",
    "        warnings.filterwarnings('ignore')\n",
    "        logger.info(\"Starting transaction processing with AMCID matching\")\n",
    "        \n",
    "        # Establish database connection\n",
    "        engine = get_db_connection(server, database, username, password)\n",
    "        \n",
    "        # Step 1: Fetch accepted orders (from your merged table)\n",
    "        logger.info(\"Fetching order data with AMCID\")\n",
    "        order_query = \"\"\"\n",
    "        SELECT DISTINCT regno, investorcode, amcid, foliono, regdate\n",
    "        FROM mf_live  \n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_df = pd.read_sql(order_query, engine)\n",
    "        \n",
    "        if order_df.empty:\n",
    "            logger.warning(\"No accepted orders found\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Step 2: Fetch transactions data with AMCID\n",
    "        logger.info(\"Fetching transactions data with AMCID\")\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT investorcode, amcid, foliono, trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \"\"\"\n",
    "        trans_df = pd.read_sql(transactions_query, engine)\n",
    "        \n",
    "        # Validate data structure\n",
    "        validate_dataframes(order_df, trans_df)\n",
    "        \n",
    "        # Step 3: Preprocess data\n",
    "        logger.info(\"Preprocessing data\")\n",
    "        \n",
    "        # Process folio numbers\n",
    "        order_df['processed_folio'] = order_df['foliono'].apply(process_folio)\n",
    "        trans_df['processed_folio'] = trans_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'])\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'])\n",
    "        \n",
    "        # Initialize results\n",
    "        results = []\n",
    "        match_count = 0\n",
    "        \n",
    "        # Step 4: Process each order using AMCID\n",
    "        logger.info(f\"Processing {len(order_df)} orders\")\n",
    "        for idx, order in order_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                conditions = [\n",
    "                    trans_df['investorcode'] == order['investorcode'],\n",
    "                    trans_df['amcid'] == order['amcid']\n",
    "                ]\n",
    "                \n",
    "                # Add folio condition if exists\n",
    "                if pd.notna(order['processed_folio']) and order['processed_folio'] != '':\n",
    "                    conditions.append(\n",
    "                        trans_df['processed_folio'] == order['processed_folio']\n",
    "                    )\n",
    "                \n",
    "                # Combine conditions\n",
    "                matching_trans = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "                \n",
    "                # Filter by registration date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'foliono': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'first_trandate': None,\n",
    "                    'has_match': False,\n",
    "                    'match_count': 0,\n",
    "                    'matching_dates': None\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    match_count += 1\n",
    "                    first_date = matching_trans['trandate'].min()\n",
    "                    \n",
    "                    result.update({\n",
    "                        'first_trandate': first_date,\n",
    "                        'has_match': True,\n",
    "                        'match_count': len(matching_trans),\n",
    "                        'matching_dates': ', '.join(\n",
    "                            matching_trans['trandate'].dt.strftime('%Y-%m-%d').sort_values().unique()\n",
    "                        )\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Processing complete. Matches found: {match_count}/{len(order_df)}\")\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Convert dates to strings for Excel output\n",
    "        date_cols = ['regdate', 'first_trandate']\n",
    "        for col in date_cols:\n",
    "            if col in result_df.columns:\n",
    "                result_df[col] = result_df[col].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\", exc_info=True)\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "            logger.info(\"Database connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuration\n",
    "        config = {\n",
    "            'server': '192.168.100.55',\n",
    "            'database': 'Wealthone',\n",
    "            'username': 'aruhat',\n",
    "            'password': 'aruhat'\n",
    "        }\n",
    "        \n",
    "        # Process data\n",
    "        logger.info(\"Starting execution\")\n",
    "        result = process_mf_transactions(**config)\n",
    "        \n",
    "        if not result.empty:\n",
    "            # Save results\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"amcid_matching_results_{timestamp}.xlsx\"\n",
    "            \n",
    "            # Select output columns\n",
    "            output_cols = [\n",
    "                'regno', 'investorcode', 'amcid', 'foliono',\n",
    "                'regdate', 'first_trandate', 'match_count',\n",
    "                'has_match', 'matching_dates'\n",
    "            ]\n",
    "            result[output_cols].to_excel(output_file, index=False)\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nProcessing Summary:\")\n",
    "            print(f\"Total orders: {len(result)}\")\n",
    "            print(f\"Matched orders: {result['has_match'].sum()}\")\n",
    "            print(f\"Results saved to: {output_file}\")\n",
    "            \n",
    "            # Show sample non-matches for verification\n",
    "            non_matches = result[~result['has_match']]\n",
    "            if not non_matches.empty:\n",
    "                print(\"\\nSample non-matching orders:\")\n",
    "                print(non_matches[['regno', 'investorcode', 'amcid']].head())\n",
    "        else:\n",
    "            print(\"Processing completed with no results. Check log for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error: {str(e)}\", exc_info=True)\n",
    "        print(\"An error occurred. Check log file for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61e98eda-06a2-4c38-a5b1-2189dfd97c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed with no results. Please check the log file for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Enhanced logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='mf_amcid_matching_debug.log',\n",
    "    filemode='w'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"Enhanced connection function with timeout and validation\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            f\"driver=ODBC+Driver+17+for+SQL+Server&\"\n",
    "            f\"timeout=30&login_timeout=10\"\n",
    "        )\n",
    "        engine = create_engine(conn_str)\n",
    "        \n",
    "        # Test connection immediately\n",
    "        with engine.connect() as test_conn:\n",
    "            test_conn.execute(\"SELECT 1\")\n",
    "            \n",
    "        logger.info(\"Database connection established successfully\")\n",
    "        return engine\n",
    "        \n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logger.error(f\"Database connection failed: {str(e)}\")\n",
    "        logger.debug(traceback.format_exc())\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected connection error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_and_preprocess_data(order_df, trans_df):\n",
    "    \"\"\"Enhanced data validation with detailed logging\"\"\"\n",
    "    logger.info(\"Starting data validation\")\n",
    "    \n",
    "    # Check if DataFrames are empty\n",
    "    if order_df.empty:\n",
    "        logger.error(\"Order DataFrame is empty\")\n",
    "        raise ValueError(\"No order data found\")\n",
    "    if trans_df.empty:\n",
    "        logger.error(\"Transactions DataFrame is empty\")\n",
    "        raise ValueError(\"No transaction data found\")\n",
    "    \n",
    "    # Required columns check\n",
    "    required_order_cols = {'regno', 'investorcode', 'amcid', 'folio', 'regdate'}\n",
    "    required_trans_cols = {'investorcode', 'amcid', 'folio', 'trandate'}\n",
    "    \n",
    "    missing_order = required_order_cols - set(order_df.columns)\n",
    "    missing_trans = required_trans_cols - set(trans_df.columns)\n",
    "    \n",
    "    if missing_order:\n",
    "        logger.error(f\"Missing columns in order data: {missing_order}\")\n",
    "    if missing_trans:\n",
    "        logger.error(f\"Missing columns in transaction data: {missing_trans}\")\n",
    "    if missing_order or missing_trans:\n",
    "        raise ValueError(\"Missing required columns\")\n",
    "    \n",
    "    # Data type conversion with error handling\n",
    "    try:\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'], errors='coerce')\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Date conversion failed: {str(e)}\")\n",
    "        logger.debug(traceback.format_exc())\n",
    "        raise\n",
    "    \n",
    "    # Check for null AMCIDs\n",
    "    if order_df['amcid'].isnull().any():\n",
    "        logger.warning(f\"Found {order_df['amcid'].isnull().sum()} orders with null AMCID\")\n",
    "    if trans_df['amcid'].isnull().any():\n",
    "        logger.warning(f\"Found {trans_df['amcid'].isnull().sum()} transactions with null AMCID\")\n",
    "    \n",
    "    logger.info(\"Data validation completed successfully\")\n",
    "    return order_df, trans_df\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main function with comprehensive debugging\"\"\"\n",
    "    try:\n",
    "        logger.info(\"=== Starting Processing ===\")\n",
    "        \n",
    "        # 1. Establish connection\n",
    "        engine = get_db_connection(server, database, username, password)\n",
    "        \n",
    "        # 2. Fetch order data with debug info\n",
    "        logger.debug(\"Executing order query\")\n",
    "        order_query = \"\"\"\n",
    "        SELECT distinct regno, investorcode, amcid, foliono, regdate\n",
    "        FROM MF_LIVE\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            order_df = pd.read_sql(order_query, engine)\n",
    "            logger.info(f\"Retrieved {len(order_df)} orders\")\n",
    "            logger.debug(f\"Order data sample:\\n{order_df.head(2)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Order query failed: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        # 3. Fetch transaction data with debug info\n",
    "        logger.debug(\"Executing transaction query\")\n",
    "        trans_query = \"\"\"\n",
    "        SELECT  investorcode, amcid, foliono, trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        WHERE trandate >= DATEADD(month, -6, GETDATE())\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trans_df = pd.read_sql(trans_query, engine)\n",
    "            logger.info(f\"Retrieved {len(trans_df)} transactions\")\n",
    "            logger.debug(f\"Transaction data sample:\\n{trans_df.head(2)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Transaction query failed: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        # 4. Validate and preprocess\n",
    "        order_df, trans_df = validate_and_preprocess_data(order_df, trans_df)\n",
    "        \n",
    "        # 5. Processing with progress tracking\n",
    "        results = []\n",
    "        match_count = 0\n",
    "        total_orders = len(order_df)\n",
    "        \n",
    "        logger.info(f\"Processing {total_orders} orders against {len(trans_df)} transactions\")\n",
    "        \n",
    "        for idx, order in order_df.iterrows():\n",
    "            try:\n",
    "                # Debug every 100th record\n",
    "                if idx % 100 == 0:\n",
    "                    logger.debug(f\"Processing order {idx}/{total_orders} - RegNo: {order['regno']}\")\n",
    "                \n",
    "                # Matching logic\n",
    "                match_cond = (\n",
    "                    (trans_df['investorcode'] == order['investorcode']) &\n",
    "                    (trans_df['amcid'] == order['amcid'])\n",
    "                )\n",
    "                \n",
    "                if pd.notna(order['foliono']):\n",
    "                    match_cond &= (trans_df['foliono'] == order['foliono'])\n",
    "                \n",
    "                if pd.notna(order['regdate']):\n",
    "                    match_cond &= (trans_df['trandate'] >= order['regdate'])\n",
    "                \n",
    "                matches = trans_df[match_cond]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'foliono': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'has_match': False,\n",
    "                    'match_count': 0,\n",
    "                    'first_match_date': None,\n",
    "                    'last_match_date': None\n",
    "                }\n",
    "                \n",
    "                if not matches.empty:\n",
    "                    match_count += 1\n",
    "                    result.update({\n",
    "                        'has_match': True,\n",
    "                        'match_count': len(matches),\n",
    "                        'first_match_date': matches['trandate'].min(),\n",
    "                        'last_match_date': matches['trandate'].max()\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # 6. Create final output\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        if result_df.empty:\n",
    "            logger.warning(\"No results generated - empty DataFrame\")\n",
    "        else:\n",
    "            logger.info(f\"Processing complete. Matches found: {match_count}/{total_orders}\")\n",
    "            logger.debug(f\"Result sample:\\n{result_df.head()}\")\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal processing error: {str(e)}\")\n",
    "        logger.debug(traceback.format_exc())\n",
    "        return None\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "            logger.info(\"Database connection closed\")\n",
    "        logger.info(\"=== Processing Completed ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuration - replace with your actual credentials\n",
    "        config = {\n",
    "            'server': '192.168.100.55',\n",
    "            'database': 'Wealthone',\n",
    "            'username': 'aruhat',\n",
    "            'password': 'aruhat'\n",
    "        }\n",
    "        \n",
    "        # Execute processing\n",
    "        logger.info(\"Starting main execution\")\n",
    "        result = process_mf_transactions(**config)\n",
    "        \n",
    "        if result is not None and not result.empty:\n",
    "            # Save results with timestamp\n",
    "            output_file = f\"amcid_results_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
    "            result.to_excel(output_file, index=False)\n",
    "            \n",
    "            # Print summary\n",
    "            print(\"\\nProcessing Summary:\")\n",
    "            print(f\"Orders Processed: {len(result)}\")\n",
    "            print(f\"Orders Matched: {result['has_match'].sum()}\")\n",
    "            print(f\"Results saved to: {output_file}\")\n",
    "            print(f\"Detailed log: mf_amcid_matching_debug.log\")\n",
    "            \n",
    "            # Show sample of non-matches for investigation\n",
    "            non_matches = result[~result['has_match']]\n",
    "            if not non_matches.empty:\n",
    "                print(\"\\nSample Non-Matched Orders:\")\n",
    "                print(non_matches[['regno', 'investorcode', 'amcid']].head())\n",
    "        else:\n",
    "            print(\"Processing completed with no results. Please check the log file for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error occurred. Check log file for details: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06d6b65b-d38f-4ccf-bfb2-a50e77f83f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed with no results. Check log file for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='mf_matching_debug.log',\n",
    "    filemode='w'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"Create database connection with error handling\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            f\"driver=ODBC+Driver+17+for+SQL+Server&\"\n",
    "            # f\"timeout=30&login_timeout=10\"\n",
    "        )\n",
    "        engine = create_engine(conn_str)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(\"SELECT 1\")\n",
    "        logger.info(\"Database connection successful\")\n",
    "        return engine\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logger.error(f\"Connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_data(order_df, trans_df):\n",
    "    \"\"\"Validate data structure and content\"\"\"\n",
    "    logger.info(\"Validating data\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_order = ['regno', 'investorcode', 'amcid', 'foliono', 'regdate']\n",
    "    required_trans = ['investorcode', 'amcid', 'foliono', 'trandate']\n",
    "    \n",
    "    missing_order = [col for col in required_order if col not in order_df.columns]\n",
    "    missing_trans = [col for col in required_trans if col not in trans_df.columns]\n",
    "    \n",
    "    if missing_order:\n",
    "        logger.error(f\"Missing columns in orders: {missing_order}\")\n",
    "    if missing_trans:\n",
    "        logger.error(f\"Missing columns in transactions: {missing_trans}\")\n",
    "    if missing_order or missing_trans:\n",
    "        raise ValueError(\"Missing required columns\")\n",
    "    \n",
    "    # Check for null AMCIDs\n",
    "    if order_df['amcid'].isnull().any():\n",
    "        logger.warning(f\"{order_df['amcid'].isnull().sum()} orders have null AMCID\")\n",
    "    if trans_df['amcid'].isnull().any():\n",
    "        logger.warning(f\"{trans_df['amcid'].isnull().sum()} transactions have null AMCID\")\n",
    "    \n",
    "    # Convert dates\n",
    "    try:\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'], errors='coerce')\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Date conversion failed: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    logger.info(\"Data validation complete\")\n",
    "    return order_df, trans_df\n",
    "\n",
    "def process_folio(folio):\n",
    "    \"\"\"Process folio numbers consistently\"\"\"\n",
    "    if pd.isna(folio):\n",
    "        return None\n",
    "    folio = str(folio).strip()\n",
    "    return folio.split('/')[0] if '/' in folio else folio\n",
    "\n",
    "def process_matches(server, database, username, password):\n",
    "    \"\"\"Main processing function with correct column names\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting MF matching process\")\n",
    "        \n",
    "        # 1. Connect to database\n",
    "        engine = get_db_connection(server, database, username, password)\n",
    "        \n",
    "        # 2. Fetch order data from mf_live\n",
    "        order_query = \"\"\"\n",
    "        SELECT regno, investorcode, amcid, foliono, CAST(LEFT(Registrationdate, CHARINDEX('T', Registrationdate) - 1) AS DATE)  regdate\n",
    "        FROM mf_live\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        logger.debug(\"Fetching order data\")\n",
    "        order_df = pd.read_sql(order_query, engine)\n",
    "        logger.info(f\"Found {len(order_df)} accepted orders\")\n",
    "        \n",
    "        if order_df.empty:\n",
    "            logger.error(\"No accepted orders found\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 3. Fetch transaction data\n",
    "        trans_query = \"\"\"\n",
    "        SELECT investorcode, amcid, foliono, trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \n",
    "        \"\"\"\n",
    "        logger.debug(\"Fetching transaction data\")\n",
    "        trans_df = pd.read_sql(trans_query, engine)\n",
    "        logger.info(f\"Found {len(trans_df)} recent transactions\")\n",
    "        \n",
    "        # 4. Validate data\n",
    "        order_df, trans_df = validate_data(order_df, trans_df)\n",
    "        \n",
    "        # 5. Preprocess folio numbers\n",
    "        logger.debug(\"Processing folio numbers\")\n",
    "        order_df['processed_folio'] = order_df['foliono'].apply(process_folio)\n",
    "        trans_df['processed_folio'] = trans_df['foliono'].apply(process_folio)\n",
    "        \n",
    "        # 6. Process matches\n",
    "        results = []\n",
    "        match_count = 0\n",
    "        \n",
    "        logger.info(f\"Matching {len(order_df)} orders against {len(trans_df)} transactions\")\n",
    "        \n",
    "        for idx, order in order_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                conditions = [\n",
    "                    trans_df['investorcode'] == order['investorcode'],\n",
    "                    trans_df['amcid'] == order['amcid']\n",
    "                ]\n",
    "                \n",
    "                # Add folio condition if exists\n",
    "                if pd.notna(order['processed_folio']):\n",
    "                    conditions.append(\n",
    "                        trans_df['processed_folio'] == order['processed_folio']\n",
    "                    )\n",
    "                \n",
    "                # Combine conditions\n",
    "                matching_trans = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "                \n",
    "                # Filter by registration date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'foliono': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'has_match': False,\n",
    "                    'match_count': 0,\n",
    "                    'first_match_date': None,\n",
    "                    'last_match_date': None\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    match_count += 1\n",
    "                    result.update({\n",
    "                        'has_match': True,\n",
    "                        'match_count': len(matching_trans),\n",
    "                        'first_match_date': matching_trans['trandate'].min(),\n",
    "                        'last_match_date': matching_trans['trandate'].max()\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "                # Log progress\n",
    "                if (idx + 1) % 100 == 0:\n",
    "                    logger.debug(f\"Processed {idx + 1} orders, found {match_count} matches\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # 7. Create results DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        if result_df.empty:\n",
    "            logger.warning(\"No matches found\")\n",
    "        else:\n",
    "            logger.info(f\"Found matches for {match_count}/{len(order_df)} orders\")\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\")\n",
    "        logger.debug(traceback.format_exc())\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "        logger.info(\"Processing completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuration - replace with your actual credentials\n",
    "        config = {\n",
    "            'server': '192.168.100.55',\n",
    "            'database': 'WEALTHONE',\n",
    "            'username': 'aruhat',\n",
    "            'password': 'aruhat'\n",
    "        }\n",
    "        \n",
    "        # Run processing\n",
    "        logger.info(\"Starting main execution\")\n",
    "        result = process_matches(**config)\n",
    "        \n",
    "        if result is not None and not result.empty:\n",
    "            # Save results\n",
    "            output_file = f\"mf_matches_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
    "            \n",
    "            # Format dates for Excel\n",
    "            date_cols = ['regdate', 'first_match_date', 'last_match_date']\n",
    "            for col in date_cols:\n",
    "                if col in result.columns:\n",
    "                    result[col] = result[col].dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Save to Excel\n",
    "            result.to_excel(output_file, index=False)\n",
    "            \n",
    "            # Print summary\n",
    "            print(\"\\nProcessing Results:\")\n",
    "            print(f\"Total Orders Processed: {len(result)}\")\n",
    "            print(f\"Orders With Matches: {result['has_match'].sum()}\")\n",
    "            print(f\"Results saved to: {output_file}\")\n",
    "            \n",
    "            # Show sample non-matches\n",
    "            non_matches = result[~result['has_match']]\n",
    "            if not non_matches.empty:\n",
    "                print(\"\\nSample Non-Matched Orders:\")\n",
    "                print(non_matches[['regno', 'investorcode', 'amcid']].head())\n",
    "        else:\n",
    "            print(\"Processing completed with no results. Check log file for details.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {str(e)}\\nCheck mf_matching_debug.log for details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da32c6ee-11cb-4349-a6bb-4c8c436b8003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed with no results. Check log file for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='mf_amcid_matching_final.log',\n",
    "    filemode='w'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"Create database connection with error handling\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            f\"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        engine = create_engine(conn_str)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(\"SELECT 1\")\n",
    "        logger.info(\"Database connection successful\")\n",
    "        return engine\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logger.error(f\"Connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_and_convert_data(order_df, trans_df):\n",
    "    \"\"\"Validate data and convert AMCID to consistent integer type\"\"\"\n",
    "    logger.info(\"Validating and converting data\")\n",
    "    \n",
    "    # Convert AMCID to integer\n",
    "    for df in [order_df, trans_df]:\n",
    "        if 'amcid' in df.columns:\n",
    "            try:\n",
    "                # First try direct conversion\n",
    "                df['amcid'] = pd.to_numeric(df['amcid'], errors='raise').astype('Int64')\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"AMCID conversion warning: {str(e)}\")\n",
    "                try:\n",
    "                    # Fallback to coerce with nulls\n",
    "                    df['amcid'] = pd.to_numeric(df['amcid'], errors='coerce').astype('Int64')\n",
    "                    if df['amcid'].isnull().any():\n",
    "                        logger.warning(f\"{df['amcid'].isnull().sum()} null AMCID values after conversion\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"AMCID conversion failed: {str(e)}\")\n",
    "                    raise\n",
    "    \n",
    "    # Convert dates\n",
    "    date_cols = {'order': 'regdate', 'trans': 'trandate'}\n",
    "    for df_type, col in date_cols.items():\n",
    "        df = order_df if df_type == 'order' else trans_df\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                if df[col].isnull().any():\n",
    "                    logger.warning(f\"{df[col].isnull().sum()} null {col} values after conversion\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"{col} conversion failed: {str(e)}\")\n",
    "                raise\n",
    "    \n",
    "    logger.info(\"Data validation and conversion complete\")\n",
    "    return order_df, trans_df\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function with proper AMCID handling\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting MF transaction processing\")\n",
    "        \n",
    "        # 1. Connect to database\n",
    "        engine = get_db_connection(server, database, username, password)\n",
    "        \n",
    "        # 2. Fetch order data from mf_live\n",
    "        order_query = \"\"\"\n",
    "        SELECT regno, investorcode, amcid, foliono, CAST(LEFT(Registrationdate, CHARINDEX('T', Registrationdate) - 1) AS DATE) regdate\n",
    "        FROM MF_LIVE\n",
    "        WHERE OrderStatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        logger.debug(\"Fetching order data\")\n",
    "        order_df = pd.read_sql(order_query, engine)\n",
    "        logger.info(f\"Retrieved {len(order_df)} orders\")\n",
    "        \n",
    "        if order_df.empty:\n",
    "            logger.error(\"No accepted orders found\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # 3. Fetch transaction data\n",
    "        trans_query = \"\"\"\n",
    "        SELECT investorcode, amcid, foliono, trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        \n",
    "        \"\"\"\n",
    "        logger.debug(\"Fetching transaction data\")\n",
    "        trans_df = pd.read_sql(trans_query, engine)\n",
    "        logger.info(f\"Retrieved {len(trans_df)} transactions\")\n",
    "        \n",
    "        # 4. Validate and convert data\n",
    "        order_df, trans_df = validate_and_convert_data(order_df, trans_df)\n",
    "        \n",
    "        # 5. Process matches\n",
    "        results = []\n",
    "        match_count = 0\n",
    "        \n",
    "        logger.info(f\"Processing {len(order_df)} orders against {len(trans_df)} transactions\")\n",
    "        \n",
    "        for idx, order in order_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                conditions = [\n",
    "                    trans_df['investorcode'] == order['investorcode'],\n",
    "                    trans_df['amcid'] == order['amcid']\n",
    "                ]\n",
    "                \n",
    "                # Add folio condition if exists\n",
    "                if pd.notna(order['foliono']):\n",
    "                    conditions.append(\n",
    "                        trans_df['foliono'].astype(str) == order['foliono'].astype(str)\n",
    "                    )\n",
    "                \n",
    "                # Combine conditions\n",
    "                matching_trans = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "                \n",
    "                # Filter by registration date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'foliono': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'has_match': False,\n",
    "                    'match_count': 0,\n",
    "                    'first_match_date': None,\n",
    "                    'last_match_date': None\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    match_count += 1\n",
    "                    result.update({\n",
    "                        'has_match': True,\n",
    "                        'match_count': len(matching_trans),\n",
    "                        'first_match_date': matching_trans['trandate'].min(),\n",
    "                        'last_match_date': matching_trans['trandate'].max()\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "                # Log progress every 100 records\n",
    "                if (idx + 1) % 100 == 0:\n",
    "                    logger.debug(f\"Processed {idx + 1} orders, found {match_count} matches\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # 6. Create results DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        if result_df.empty:\n",
    "            logger.warning(\"No results generated\")\n",
    "        else:\n",
    "            logger.info(f\"Found {match_count} matches out of {len(order_df)} orders\")\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\")\n",
    "        logger.debug(traceback.format_exc())\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "        logger.info(\"Processing completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuration\n",
    "        config = {\n",
    "            'server': '192.168.100.55',\n",
    "            'database': 'Wealthone',\n",
    "            'username': 'aruhat',\n",
    "            'password': 'aruhat'\n",
    "        }\n",
    "        \n",
    "        # Run processing\n",
    "        logger.info(\"Starting main execution\")\n",
    "        result = process_mf_transactions(**config)\n",
    "        \n",
    "        if result is not None and not result.empty:\n",
    "            # Save results\n",
    "            output_file = f\"mf_amcid_results_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
    "            \n",
    "            # Format dates for Excel\n",
    "            date_cols = ['regdate', 'first_match_date', 'last_match_date']\n",
    "            for col in date_cols:\n",
    "                if col in result.columns:\n",
    "                    result[col] = result[col].dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Save to Excel\n",
    "            result.to_excel(output_file, index=False)\n",
    "            \n",
    "            # Print summary\n",
    "            print(\"\\nProcessing Summary:\")\n",
    "            print(f\"Total Orders Processed: {len(result)}\")\n",
    "            print(f\"Orders With Matches: {result['has_match'].sum()}\")\n",
    "            print(f\"Results saved to: {output_file}\")\n",
    "            \n",
    "            # Show sample non-matches for investigation\n",
    "            non_matches = result[~result['has_match']]\n",
    "            if not non_matches.empty:\n",
    "                print(\"\\nSample Non-Matched Orders:\")\n",
    "                print(non_matches[['regno', 'investorcode', 'amcid']].head())\n",
    "        else:\n",
    "            print(\"Processing completed with no results. Check log file for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error occurred: {str(e)}\\nSee mf_amcid_matching_final.log for details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9c266e-23f4-4662-b215-2b4b82cdd299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'str' object has no attribute 'astype'\n",
      "No results returned\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function with direct date handling\"\"\"\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        \n",
    "        # Fetch order data with proper date conversion\n",
    "        order_query = \"\"\"\n",
    "        SELECT \n",
    "            regno, \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            foliono, \n",
    "            CAST(LEFT(registrationdate, CHARINDEX('T', registrationdate) - 1) AS DATE) AS regdate\n",
    "        FROM mf_live\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_df = pd.read_sql(order_query, engine)\n",
    "        \n",
    "        if order_df.empty:\n",
    "            print(\"No accepted orders found\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Fetch transaction data\n",
    "        trans_query = \"\"\"\n",
    "        SELECT \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            foliono, \n",
    "            trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        WHERE trandate >= DATEADD(month, -6, GETDATE())\n",
    "        \"\"\"\n",
    "        trans_df = pd.read_sql(trans_query, engine)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'])\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'])\n",
    "        \n",
    "        # Initialize results\n",
    "        results = []\n",
    "        \n",
    "        # Process each order\n",
    "        for _, order in order_df.iterrows():\n",
    "            # Create matching conditions\n",
    "            conditions = [\n",
    "                trans_df['investorcode'] == order['investorcode'],\n",
    "                trans_df['amcid'] == order['amcid']\n",
    "            ]\n",
    "            \n",
    "            # Add folio condition if exists\n",
    "            if pd.notna(order['foliono']):\n",
    "                conditions.append(\n",
    "                    trans_df['foliono'].astype(str) == order['foliono'].astype(str)\n",
    "                )\n",
    "            \n",
    "            # Combine conditions\n",
    "            matching_trans = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "            \n",
    "            # Filter by registration date\n",
    "            if pd.notna(order['regdate']):\n",
    "                matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "            \n",
    "            # Prepare result\n",
    "            result = {\n",
    "                'regno': order['regno'],\n",
    "                'investorcode': order['investorcode'],\n",
    "                'amcid': order['amcid'],\n",
    "                'foliono': order['foliono'],\n",
    "                'regdate': order['regdate'],\n",
    "                'has_match': False,\n",
    "                'first_match_date': None\n",
    "            }\n",
    "            \n",
    "            if not matching_trans.empty:\n",
    "                result.update({\n",
    "                    'has_match': True,\n",
    "                    'first_match_date': matching_trans['trandate'].min()\n",
    "                })\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    server = '192.168.100.55'\n",
    "    database = 'WEALTHONE'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    # Process data\n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        # Save to Excel\n",
    "        output_file = \"mf_matching_results.xlsx\"\n",
    "        \n",
    "        # Format dates\n",
    "        result['regdate'] = result['regdate'].dt.strftime('%Y-%m-%d')\n",
    "        result['first_match_date'] = result['first_match_date'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        result.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nOrders processed: {len(result)}\")\n",
    "        print(f\"Orders with matches: {result['has_match'].sum()}\")\n",
    "        \n",
    "        # Show sample non-matches\n",
    "        non_matches = result[~result['has_match']]\n",
    "        if not non_matches.empty:\n",
    "            print(\"\\nSample non-matching orders:\")\n",
    "            print(non_matches[['regno', 'investorcode', 'amcid']].head())\n",
    "    else:\n",
    "        print(\"No results returned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e99a69-ac83-4cc6-8d96-cb1e5c06d7b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 138\u001b[0m\n\u001b[0;32m    135\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_match_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_match_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    137\u001b[0m result\u001b[38;5;241m.\u001b[39mto_excel(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 138\u001b[0m result\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINVESTOR_MATCHES\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mengine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "server = '192.168.100.55'\n",
    "database = 'WEALTHONE'\n",
    "username = 'aruhat'\n",
    "password = 'aruhat'\n",
    "\n",
    "engine1 = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        ) \n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function with corrected folio handling\"\"\"\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        \n",
    "        # Fetch order data with proper date conversion\n",
    "        order_query = \"\"\"\n",
    "        SELECT \n",
    "            regno, \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            foliono, \n",
    "            CAST(LEFT(registrationdate, CHARINDEX('T', registrationdate) - 1) AS DATE) AS regdate\n",
    "        FROM mf_live\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_df = pd.read_sql(order_query, engine)\n",
    "        \n",
    "        if order_df.empty:\n",
    "            print(\"No accepted orders found\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Fetch transaction data\n",
    "        trans_query = \"\"\"\n",
    "        SELECT \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            CASE \n",
    "\t\t\t\tWHEN CHARINDEX('/', FolioNo) > 0 THEN LEFT(FolioNo, CHARINDEX('/', FolioNo) - 1)\n",
    "\t\t\tELSE FolioNo\n",
    "\t\t\tEND AS foliono, \n",
    "            trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "     \n",
    "        \"\"\"\n",
    "        trans_df = pd.read_sql(trans_query, engine)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'])\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'])\n",
    "        \n",
    "        # Initialize results\n",
    "        results = []\n",
    "        \n",
    "        # Process each order\n",
    "        for _, order in order_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                conditions = [\n",
    "                    trans_df['investorcode'] == order['investorcode'],\n",
    "                    trans_df['amcid'] == order['amcid']\n",
    "                ]\n",
    "                \n",
    "                # Add folio condition if exists (corrected handling)\n",
    "                if pd.notna(order['foliono']) and str(order['foliono']).strip() != '':\n",
    "                    folio_str = str(order['foliono']).strip()\n",
    "                    conditions.append(\n",
    "                        trans_df['foliono'].apply(lambda x: str(x).strip() == folio_str\n",
    "                    )\n",
    "                    )\n",
    "                # Combine conditions\n",
    "                matching_trans = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "                \n",
    "                # Filter by registration date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'foliono': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'has_match': False,\n",
    "                    'first_match_date': None,\n",
    "                    'match_count': 0\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    result.update({\n",
    "                        'has_match': True,\n",
    "                        'first_match_date': matching_trans['trandate'].min(),\n",
    "                        'match_count': len(matching_trans)\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    server = '192.168.100.55'\n",
    "    database = 'WEALTHONE'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    # Process data\n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        # Save to Excel\n",
    "        output_file = \"mf_matching_results.xlsx\"\n",
    "        \n",
    "        # Format dates\n",
    "        result['regdate'] = result['regdate'].dt.strftime('%Y-%m-%d')\n",
    "        result['first_match_date'] = result['first_match_date'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        result.to_excel(output_file, index=False)\n",
    "        result.to_sql('INVESTOR_MATCHES', con=engine1, if_exists=\"append\", index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nOrders processed: {len(result)}\")\n",
    "        print(f\"Orders with matches: {result['has_match'].sum()}\")\n",
    "        \n",
    "        # Show sample non-matches\n",
    "        non_matches = result[~result['has_match']]\n",
    "        if not non_matches.empty:\n",
    "            print(\"\\nSample non-matching orders:\")\n",
    "            print(non_matches[['regno', 'investorcode', 'amcid', 'foliono']].head())\n",
    "            \n",
    "    else:\n",
    "        print(\"No results returned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333ea489-8a1f-4e3d-ba63-f51d154696c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: The type of regno is not a SQLAlchemy type\n",
      "No results returned\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "\n",
    "def process_mf_transactions(server, database, username, password):\n",
    "    \"\"\"Main processing function with SQL insertion\"\"\"\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "            \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        \n",
    "        # Fetch order data with proper date conversion\n",
    "        order_query = \"\"\"\n",
    "        SELECT \n",
    "            regno, \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            foliono, \n",
    "            CAST(LEFT(registrationdate, CHARINDEX('T', registrationdate) - 1) AS DATE) AS regdate\n",
    "        FROM mf_live\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "        \"\"\"\n",
    "        order_df = pd.read_sql(order_query, engine)\n",
    "        \n",
    "        if order_df.empty:\n",
    "            print(\"No accepted orders found\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Fetch transaction data\n",
    "        trans_query = \"\"\"\n",
    "        SELECT \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            foliono, \n",
    "            trandate\n",
    "        FROM MUTUALFUND_TRANSACTIONS\n",
    "        WHERE trandate >= DATEADD(month, -6, GETDATE())\n",
    "        \"\"\"\n",
    "        trans_df = pd.read_sql(trans_query, engine)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'])\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'])\n",
    "        \n",
    "        # Initialize results\n",
    "        results = []\n",
    "        \n",
    "        # Process each order\n",
    "        for _, order in order_df.iterrows():\n",
    "            try:\n",
    "                # Create matching conditions\n",
    "                conditions = [\n",
    "                    trans_df['investorcode'] == order['investorcode'],\n",
    "                    trans_df['amcid'] == order['amcid']\n",
    "                ]\n",
    "                \n",
    "                # Add folio condition if exists\n",
    "                if pd.notna(order['foliono']) and str(order['foliono']).strip() != '':\n",
    "                    folio_str = str(order['foliono']).strip()\n",
    "                    conditions.append(\n",
    "                        trans_df['foliono'].apply(lambda x: str(x).strip() == folio_str)\n",
    "                    )\n",
    "                \n",
    "                # Combine conditions\n",
    "                matching_trans = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "                \n",
    "                # Filter by registration date\n",
    "                if pd.notna(order['regdate']):\n",
    "                    matching_trans = matching_trans[matching_trans['trandate'] >= order['regdate']]\n",
    "                \n",
    "                # Prepare result\n",
    "                result = {\n",
    "                    'regno': order['regno'],\n",
    "                    'investorcode': order['investorcode'],\n",
    "                    'amcid': order['amcid'],\n",
    "                    'foliono': order['foliono'],\n",
    "                    'regdate': order['regdate'],\n",
    "                    'has_match': False,\n",
    "                    'first_match_date': None,\n",
    "                    'match_count': 0,\n",
    "                    'processing_date': datetime.now()\n",
    "                }\n",
    "                \n",
    "                if not matching_trans.empty:\n",
    "                    result.update({\n",
    "                        'has_match': True,\n",
    "                        'first_match_date': matching_trans['trandate'].min(),\n",
    "                        'match_count': len(matching_trans)\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing order {order['regno']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        if not result_df.empty:\n",
    "            # Insert results into SQL table\n",
    "            result_df.to_sql(\n",
    "                name='mf_matching_results',  # Your target table name\n",
    "                con=engine,\n",
    "                if_exists='append',  # Append to existing data\n",
    "                index=False,\n",
    "                dtype={\n",
    "                    'regno': pd.StringDtype(),\n",
    "                    'investorcode': pd.StringDtype(),\n",
    "                    'amcid': pd.Int64Dtype(),\n",
    "                    'foliono': pd.StringDtype(),\n",
    "                    'regdate': pd.Timestamp,\n",
    "                    'has_match': pd.StringDtype(),\n",
    "                    'first_match_date': pd.Timestamp,\n",
    "                    'match_count': pd.Int64Dtype(),\n",
    "                    'execution_time': pd.Timestamp\n",
    "                }\n",
    "            )\n",
    "            print(\"Results successfully inserted into SQL table\")\n",
    "        \n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    server = '192.168.100.55'\n",
    "    database = 'Wealthone'\n",
    "    username = 'aruhat'\n",
    "    password = 'aruhat'\n",
    "    \n",
    "    # Process data\n",
    "    result = process_mf_transactions(server, database, username, password)\n",
    "    \n",
    "    if not result.empty:\n",
    "        # Save to Excel\n",
    "        output_file = \"mf_matching_results.xlsx\"\n",
    "        \n",
    "        # Format dates\n",
    "        result['regdate'] = result['regdate'].dt.strftime('%Y-%m-%d')\n",
    "        result['first_match_date'] = result['first_match_date'].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        result.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nOrders processed: {len(result)}\")\n",
    "        print(f\"Orders with matches: {result['has_match'].sum()}\")\n",
    "        \n",
    "        # Show sample non-matches\n",
    "        non_matches = result[~result['has_match']]\n",
    "        if not non_matches.empty:\n",
    "            print(\"\\nSample non-matching orders:\")\n",
    "            print(non_matches[['regno', 'investorcode', 'amcid', 'foliono']].head())\n",
    "    else:\n",
    "        print(\"No results returned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57c27987-9da2-4057-b507-12b740878a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1442 records into SQL\n",
      "Saved results to Excel\n",
      "Processing completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "\n",
    "# Database configuration\n",
    "server = '192.168.100.55'\n",
    "database = 'WEALTHONE'\n",
    "username = 'aruhat'\n",
    "password = 'aruhat'\n",
    "\n",
    "# Create database connection\n",
    "engine = create_engine(\n",
    "    f\"mssql+pyodbc://{username}:{password}@{server}/{database}?\"\n",
    "    \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fetch order data with date conversion\n",
    "    order_df = pd.read_sql(\"\"\"\n",
    "        SELECT \n",
    "            regno, \n",
    "            investorcode, \n",
    "            amcid, \n",
    "            foliono, \n",
    "            CAST(LEFT(registrationdate, CHARINDEX('T', registrationdate) - 1) AS DATE) AS regdate\n",
    "        FROM mf_live\n",
    "        WHERE orderstatus = 'Accepted'\n",
    "    \"\"\", engine)\n",
    "    \n",
    "    if order_df.empty:\n",
    "        print(\"No accepted orders found\")\n",
    "    else:\n",
    "        # Fetch transaction data\n",
    "        trans_df = pd.read_sql(\"\"\"\n",
    "            SELECT \n",
    "                investorcode, \n",
    "                amcid, \n",
    "                foliono, \n",
    "                trandate\n",
    "            FROM MUTUALFUND_TRANSACTIONS\n",
    "            \n",
    "        \"\"\", engine)\n",
    "        \n",
    "        # Convert dates\n",
    "        order_df['regdate'] = pd.to_datetime(order_df['regdate'])\n",
    "        trans_df['trandate'] = pd.to_datetime(trans_df['trandate'])\n",
    "        \n",
    "        # Process matches\n",
    "        results = []\n",
    "        for _, order in order_df.iterrows():\n",
    "            # Create matching conditions\n",
    "            conditions = [\n",
    "                trans_df['investorcode'] == order['investorcode'],\n",
    "                trans_df['amcid'] == order['amcid']\n",
    "            ]\n",
    "            \n",
    "            # Add folio condition if exists\n",
    "            if pd.notna(order['foliono']) and str(order['foliono']).strip():\n",
    "                folio_str = str(order['foliono']).strip()\n",
    "                conditions.append(trans_df['foliono'].apply(lambda x: str(x).strip() == folio_str))\n",
    "            \n",
    "            # Find matches\n",
    "            matches = trans_df[pd.concat(conditions, axis=1).all(axis=1)]\n",
    "            if pd.notna(order['regdate']):\n",
    "                matches = matches[matches['trandate'] >= order['regdate']]\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'regno': order['regno'],\n",
    "                'investorcode': order['investorcode'],\n",
    "                'amcid': order['amcid'],\n",
    "                'foliono': order['foliono'],\n",
    "                'regdate': order['regdate'],\n",
    "                'has_match': not matches.empty,\n",
    "                'first_match_date': matches['trandate'].min() if not matches.empty else None,\n",
    "                'execution_time': datetime.now()\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        # Create DataFrame and save to SQL\n",
    "        result_df = pd.DataFrame(results)\n",
    "        if not result_df.empty:\n",
    "            result_df.to_sql(\n",
    "                'INVESTOR_MATCHES',\n",
    "                engine,\n",
    "                if_exists='append',\n",
    "                index=False\n",
    "            )\n",
    "            print(f\"Inserted {len(result_df)} records into SQL\")\n",
    "            \n",
    "            # Also save to Excel\n",
    "            result_df.to_excel(\"results.xlsx\", index=False)\n",
    "            print(\"Saved results to Excel\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "finally:\n",
    "    engine.dispose()\n",
    "    print(\"Processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f255b-7469-4c61-ae1d-63a06f03613b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
